## Repositório com os exercícios dos cursos Alura da formação de Data Science

![certificado](https://github.com/RafaelxFernandes/Data_Science/blob/main/Certificado%20de%20Rafael%20da%20Silva%20Fernandes%20Forma%C3%A7%C3%A3o%20Data%20Science%20-%20Cursos%20Alura-1.png)

### 1 - Introdução à Numpy
- trabalhando com arrays Numpy
- operações matemáticas
- operações e métodos de listas
- loops aninhados e list comprehension
- seleções com arrays Numpy
- atributos e métodos de arrays Numpy
- estatísticas com arrays Numpy


### 2 - Introdução à Pandas
- trabalhando com tuplas
- criação, operações e métodos de dicionários
- built-in functions de Python
- estruturas de dados (Series e DataFrame)
- queries e iterações com DataFrames
- tratamento de dados


### 3 - Dados, visualizações e estatística
- análise de dados
- plotagem (histplot, boxplot, distplot, catplot, barplot, pieplot)
- revisando o papel da média, mediana, medidas de tendência central, dispersão, desvio padrão, box plot, histograma


### 4 - Pandas: Tratando e analisando dados
- instalando MiniConda no Google Colab
- importando base de dados
- informações gerais sobre a base de dados
- trabalhando com a mesma base de dados em outros formatos (JSON, TXT, XLSX, HTML)
- organizando a visualização
- criação de estruturas de dados (Series e DataFrame)
- métodos de DataFrames
- exportando a base de dados
- organizando DataFrames (sort)
- tratamento de dados faltantes
- métodos de interpolação
- criando e excluindo colunas no DataFrame
- contadores
- criando agrupamentos
- estatísticas descritivas
- criando faixas de valor
- identificando e removendo outliers
- introdução à Matplotlib


### 5 - Estatística com Python, Parte 1: Frequências e Medidas
- variáveis qualitativas ordinais
- variáveis qualitativas nominais
- variáveis quantitativas discretas
- variáveis quantitativas contínuas
- análise da distribuição de frequência e histogramas
- value_counts e crosstab
- definindo o número de classes (regra de Sturges)
- introdução à Seaborn (distplot e boxplot)
- variância populacional e amostral
- desvio padrão populacional e amostral


### 6 - Estatística com Python, Parte 2: Probabilidade e Amostragem
- experimento binomial
- média da distribuição binomial
- desvio padrão da distribuição binomial
- combinações
- experimento Poisson
- média da distribuição Poisson
- desvio padrão da distribuição Poisson
- distribuição normal
- tabelas padronizadas
- teorema do limite central
- intervalo de confiança para a média da população com desvio padrão populacional conhecido e desconhecido


### 7 - Regressão Linear, Parte 1: Relações e Prevendo resultados
- estatísticas descritivass
- matriz de correlação
- análises gráficas das variáveis dependente e independentes
- distribuição de frequências
- gráficos de dispersão entre as variáveis do dataset (pairplot, jointplot, lmplot)
- regressão linear com train_test_split da biblioteca scikit-learn
- função de regressão com três variáveis explicativas
- obtendo o coeficiente de determinação (R²)
- gerando previsão pontual e criando um simulador simples
- obtendo intercepto do modelo
- obtendo os coeficientes de regressão
- gerando as previsões do modelo
- métricas de regressão
- erro quadrático médio
- raiz do erro quadrático médio
- salvando o modelo estimado (pickle)


### 8 - Regressão Linear, Parte 2: Técnicas avançadas de modelagem
- estatísticas descritivas
- matriz de correlação
- gráficos de dispersão entre as variáveis do dataset
- distribuição normal
- aplicando a transformação logarítmica 
- regressão linear com train_test_split da biblioteca scikit-learn
- modelo log-linear
- introdução à biblioteca statsmodels
- estimando o modelo com statsmodels
- avaliando as estatísticas de teste do modelo por meio de mínimos quadrados ordinários
- obtendo o coeficiente de determinação (R²)
- gerando previsão pontual e criando um simulador simples


### 9 - Data Visualization, Parte 1: Introdução ao design de gráficos
- quais gráficos são mais adequados para mostrar uma determianda informação
- aprimorando gráficos retirando informações desnecessárias
- posicionamento de elementos no gráfico segundo padrões de leitura
- como melhor destacar uma informação


### 10 - Data Visualization, Parte 2: Escolhendo o melhor gráfico
- princípios por trás da construção dos gráficos
- principais relações que gráficos podem demonstrar
- como o tipo de variável é importante.
- apresente melhor suas informações


### 11 - Data Visualization, Criando gráficos com o Matplotlib
- conversão para datetime
- gráfico de linha
- selecionar apenas uma parte dos dados para a visualização
- adicionar mais de um eixo na mesma visualização
- mover os eixos x e y
- fazer gráficos com mais de uma cor
- adicionar linhas de restrição
- adicionar setas
- desenhar um gráfico de barras
- desenhar um gráfico de pizza
- fazer um gráfico de dispersão
- aplicar filtros em conjuntos de dados
- fazer um gráfico de caixas univariável
- fazer um gráfico de caixas multivariável
- fazer um histograma
- normalizar um histograma
- adicionar anotações matemáticas
- salvar figuras
- combinar mais de uma imagem em apenas uma


### 12 - Introdução à Testes Estatísticos com Python
- gerar um histograma
- gerar um boxplot
- fazer uma query
- gerar histogramas de maneira cumulativa
- remover valores NaN
- separação de dados com quantile()
- descobrir intervalo de confiança com tconfint()
- descrever nossos dados de forma estatística
- o que é, como utilizar e quando utilizar o Teste Z e o Teste T
- gerar um intervalo de confiança das médias de nossas distribuições
- utilizar o get_compare() do statsmodels
- comparar médias
- utilizar o summary()
- utilizar o seaborn para mostrar gráfico
- comparar médias diferentes
- utilizar o normaltest
- teste não paramétrico
- utilizar o ranksums

### 13 - Introdução à Experimentação: Análise de Experimentos
- discernir quais fontes são válidas para a coleta de dados
- definir os objetivos do experimento, assim como identificar as variáveis manipuláveis e a resposta do experimento
- como limitar a área de experimentação
- planejamentos fatoriais
- usar a biblioteca pyDOE2 para gerar planejamentos fatoriais
- fazer análises gráficas preliminares do experimento
- propor um modelo estatístico
- ajustar o modelo estatístico aos dados experimentais usando o StatsModel
- o significado de graus de liberdade
- calcular os graus de liberdade dos resíduos
- fazer a análise de significância estatística dos parâmetros do modelo
- construir e interpretar um gráfico normalizado de pareto
- atualizar hipóteses iniciais a medida que novas informações são coletadas
- propor novos modelos para melhor representar a realidade de um experimento
- analisar um gráfico de predito por observado com a finalidade de inferir a qualidade da representatividade de um modelo
- relacionar o coeficiente de correlação R2 com a qualidade do ajuste e com os resultados apresentados por um gráfico de preditos por observados
- construir e interpretar mapas de cores
- inserir linhas nos mapas de cores para facilitar a interpretação dos resultados

### 14 - Análise para Saúde e Medicina
- importar raw csv
- data visualization no cotidiano
- plotagem dos dados com pandas e matplotlib
- calcular diferenciação
- fontes de dados recomendadas
- interpretação e exposição dos dados
- histogramas e resumindo informações
- usos do scatterplot e displot


### 15 - Visualização de Dados para Saúde e Medicina
- data visualization
- filtrar por coluna e valor de interesse
- substituir valores de True e False com numpy
- calcular soma e diferença das colunas
- transpor matriz
- juntando dataset distintos
- trabalhando textos com pandas


### 16 - Python Pandas Técnicas Avançadas

- alterar algumas configurações do Colab e do Pandas
- carregar arquivos no formato JSON em uma DataFrame do pandas
- carregar arquivos no formato XLSX em uma DataFrame do pandas
- como converter o formato JSON em um formato tabular
- trabalhar com dados no formato textual
- trabalhar com dados textuais juntamente com objetos do pandas
- utilizar métodos de string para fazer conversões de tipo
- conhecemos os métodos do pandas para empilhar objetos do pandas
- técnicas de tratamento de dados para gerar compatibilizações
- métodos para juntar DataFrames com o uso de variáveis de ligação
- extração de informações de dados em formato de texto
- criar categorias a partir de dados categorizados
- criar categorias a partir de dados numéricos
- criar colunas em um DataFrame a partir de outras informações
- método de aplicação de funções lambda nos eixos de um DataFrame
- métodos de agregação do pandas
- técnicas de geração de tabelas de resumo
- formas de reorganizar as informações de um DataFrame
- criar tabelas dinâmicas a partir de DataFrames
- formas de pesquisa e substituição de informações com o método where
- trabalhar com dados em formato de lista dentro de objetos do pandas
- métodos de estilização de DataFrames


### 17 - Introdução à Análise de Séries Temporais

- verificar se havia dados nulos com o comando dataset.isna().sum()
- aperfeiçoar o gráfico incluindo uma nova palette de cor, incluindo título e labels com tamanho adequado descrevendo melhor do que se trata
- aplicar a técnica de Decomposição de uma time series, para mensurar o crescimento mês a mês
- utilizamos a função diff() para decomposição das vendas para criar o aumento, e do aumento para descobrir a aceleração
- executar a função de Autocorrelação para descobrir o nível de correlação das vendas, do aumento e da aceleração
- importância da técnica de Decomposição na análise dos dados
- analisar os dados e descobrir um padrão repetitivo no movimento deles dentro de um período de tempo fixo, na qual é chamado de Sazonalidade
- investigar o que causava a sazonalidade
- técnica de normalização de time series para minimizar as frequências pela quantidade de dias de finais de semana de cada mês
- análise de uma time series importando da biblioteca statsmodels.tsa.seasonal a função seasonal_decompose, que nos mostra o que é a nossa observação, tendência, sazonalidade e ruído de uma só vez
- ruído na Time Series
- minimizar os ruídos de uma time series aplicando a técnica da média móvel
- criar um gráfico com a média móvel de 7 e 21 dias e comparamos com nossa observação


### 18 - Análise de Série Temporal: COVID-19

- análise exploratória visual simples para séries temporais
- o que é o crescimento exponencial e como ele se aplica ao contexto de pandemias
- transformada logarítmica e como ela pode nos ajudar a visualizar melhor dados que apresentam comportamento de crescimento exponencial
- calcular a aceleração (ou desaceleração da pandemia) e como plotar corretamente essa nova variável
- criar funções para evitar a repetição de códigos
- como utilizar a ferramenta matemática da média móvel para diminuir as oscilações causadas
- o que significa matematicamente a correlação entre as variáveis e também suas implicações
- como calcular a autocorrelação em séries temporais e como interpretá-la
- como modificar a variável de estudo pode influenciar os valores de autocorrelação devido à dependência temporal
- o que significa sazonalidade e como ela estava presente em nossos dados
- criar novas variáveis com as que já temos, facilitando a análise. Este processo também é conhecido como “feature engineering”
- como utilizar um dicionário e o mapeamento de bancos de dados para traduzir os dias da semana de inglês para português
- utilizar a função para criarmos um único gráfico mostrando informações sobre dia da semana, dia do mês e mês com pairplot


### 19 - Previsões de série temporal: COVID-19
- decomposição: filtrar os dados para os estados de interesse e decompor nossa série temporal em componentes
- tendência e sazonalidade: identificar os padrões de sazonalidade e de tendência para diferentes séries temporais
- como definir uma série estacionária e realizar o teste ADF para checar se uma série é ou não estacionária
- autocorrelação e o que ela tem a nos dizer sobre as séries temporais
- conceito de autocorrelação parcial e como ele nos ajuda a entender melhor o comportamento de séries temporais com sazonalidade
- que tipo de métrica podemos utilizar para saber se o modelo ARIMA é bom ou não
- o que significa cada um dos parâmetros do modelo ARIMA
- como rodar o SARIMAX para diversos parâmetros e comparar a melhor métrica de performance
- como identificar a qualidade dos nossos modelos por meio do gráfico Q-Q, dos resíduos, do histograma e do correlograma
- qual a importância de utilizar um intervalo de confiança
- quando utilizar as funções get_forecast() e get_prediction()
- como utilizar dados que temos para testar nosso modelo antes de realizar previsões para o futuro
- como fazer o uso do ARIMA sazonal com outros dados
- observamos que séries com tendência menor acabam apresentando resultados melhores com o uso do ARIMA sazonal
- é mais importante ainda utilizar um período de previsão menor, uma vez que oscilações e resíduos se tornam mais importantes, devido à amplitude menor dos dados originais


### 20 - Python Scikit-Learn: Regressão, classificação e clustering
- Treinar os dados
- o que é classificação
- como identificar problemas de classificação
- construir uma árvore de decisão
- como prever um problema de classificação
- o que é acurácia
- o dummy classifier
- o que é regressão
- como identificar problemas de regressão
- o que é regressão linear
- como prever um problema de regressão
- o que é clustering
- como identificar problemas de clustering
- algoritmo KMeans


### 21 - Clustering: extraindo padrões de dados
- o problema da falta de rótulos
- a diferença entre classificação e clusterização
- analisar os atributos de modo geral
- aimpar os dados
- normalizar os dados
- rodar o algoritmo k-means
- critérios utilizados para validar os clusters: compactação e separação
- passo a passo para calcular o coeficiente de silhouette
- utilizar a função silhouette_score() do scikit-learn
- passo a passo para calcular o índice davies bouldin
- utilizar a função davies_bouldin_score() do scikit-learn
- passo a passo para calcular o índice calinski harabasz
- utilizar a função calinski_harabasz_score() do scikit-learn
- comparar diferentes configurações do k-means por meio da validação relativa
- validar a estrutura dos clusters
- verificar a estabilidade dos clusters
- gerar gráficos para a visualização dos clusters
- interpretar os clusters por meio dos gráficos
- dificuldade da atividade de visualização de clusters
- obter e analisar estatísticas sobre os valores dos atributos
- calcular a variância dos centróides dos clusters
- selecionar os melhores atributos para servir de base para a interpretação
- analisar os dados dos clusters
- interpretar os dados dos clusters
- extrair os padrões que caracterizam cada cluster

### 22 - Machine Learning: Introdução a classificação com SKLearn

- definir características (features) do que desejamos classificar
- classificar em categorias
- utilizar o módulo linearSVC e accuracy_score
- utilizar o método fit
- prever dados com a função predict
- calcular a taxa de acerto do modelo
- comparar testes e previsões
- separar dados para treino e teste
- estratificar splits
- criação de um algoritmo base
- utilizar a função arange do numpy
- decision boundary
- utilizar o módulo Support Vector Machine
- gerar valores randômicos com o módulo SVC
- utilizar o módulo Standard Scale
- utilizar o módulo DummyClassifier

### 23 - Clusterização de dados: Segmentação de clientes

- quais as principais etapas em um problema de segmentação
- que tipo de dados vamos precisar obter
- como a análise exploratória pode ajudar a identificar insights
- como adicionar textos informativos em gráficos
- modelos RFM (recência, frequência e monetaridade)
- como funciona o método k-means
- como usar a regra do cotovelo para definir o número de clusters
- como usar uma regra matemática para confirmar o número de clusters
- como clusterizar os dados usando kmeans
- como ordenar os dados de forma que o número de cluster sirva como pontuação
- criar funções de forma simplificada ao segmentar as operações
- criar um modelo de pontuação com base nos clusters
- fazer visualizações com scatterplot
- identificar o comportamento dos clientes
